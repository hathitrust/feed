---
# Basic directories and configuration
feed_home: /path/to/feed

admin_email: EMAIL

database:
# Datasouce must should be dbi:mysql:database:host
  datasource: dbi:mysql:HOST:DATABASE
  username: USERNAME
  password: PASSWORD

# Paths to various tools

imagemagick: /l/local/ImageMagick-6.6.9-8/bin/convert

xerces: "$feed_home/bin/validateCache /ram/schema.cache"
kdu_munge: /l/local/bin/kdu_munge
# path to kdu_compress from kakadu 6.4 - the version is important because
# different versions of kakadu interpret compression settings differently.
kdu_compress: /l/local/bin/kdu_compress

jhove: /l/local/bin/jhove
jhoveconf: /l/local/jhove/conf/jhove.conf

l4p:
  root_logger: 'INFO, file'
  config: $feed_home/etc/config.l4p

premis_config: $feed_home/etc/premis.yaml

# Ram disk and staging directory configuration
ram_disk: /ram
ram_fill_limit: 0.8
ram_disk_max_job_size: 1073741824
ram_stage: $ram_disk/feed

disk_stage: DISK_STAGING_DIRECTORY

staging:
  download: $disk_stage/download
  ingest: $ram_stage/ingest
  zip: $ram_stage/zip
  zipfile: $ram_stage/zipfile
  preingest: $ram_stage/preingest
  disk:
    ingest: $disk_stage/ingest
    preingest: $disk_stage/preingest
    zip: $disk_stage/zip
    zipfile: $disk_stage/zipfile
  grin: $disk_stage/grin
  
repository:
# The directory in which symbolic links will be created to each volume, and
# in which volumes can be found that are already in the repository
  link_dir: /sdr1/obj
  # The directory into which volumes will be loaded 
  obj_dir: /sdr6/obj

# feedd configuration
daemon:
  release_states:
    - punted
    - collated
    - held
    - rights
  stop_file: $feed_home/etc/STOPFEED
  
volumes_in_process_limit: 5
failure_limit: 5
stop_on_error: 0
fork: 0

# handle server configuration

handle:
  repo_url_base: http://babel.hathitrust.org/cgi/pt?id=
  root_admin: 0.NA/2027
  local_admin: 2027/mdp
  database:
    datasource: dbi:mysql:DATABASE:HOST
    username: USER
    password: PASSWORD

# metadata (rights & bibliographic records) servers & locations
metadata_host: USER@HOST
metadata_dir: METADATA_DIR 

# ssh key to use when depositing or picking up metadata
ssh_key: RSA_KEY

ingest_logs:
  host: 
    - libadm@carafe
    - libadm@growler
  source: /htapps/aelkiss.babel/stage/log
  glob: '*.gz'
  dest: /l1/www.lib/web/sites/www.hathitrust.org/files/ingest_logs/
  archive: $source/archive

ingest_reports:
  host:
    - libadm@carafe
    - libadm@growler
  source: /htapps/aelkiss.babel/stage/reports
  glob: '*.gz'
  dest: /l1/www.lib/web/sites/www.hathitrust.org/files/ingest_reports/
  archive: $source/archive

bibrecords:
# user & host to pick up from
  host: $metadata_host 
# source directory on host to pick up from
  source: $metadata_dir 
# glob of files to copy
  glob: '*meta.txt' 
# local directory to copy files to
  dest: $disk_stage/bibrecords 
# directory on host to move files to after pickup
  archive: $source/archive 

rights:
# Database with the rights_current table
  database: dbi:mysql:mdp:mysql-htdev

# Email address of the person who should receive an email notification when new rights files are available
  email: TO_EMAIL
  from_email: FROM_EMAIL

# Location of rights files
  rights_dir: $disk_stage/rights
# Where to archive rights files after they are loaded
  archive: $rights_dir/archive

# Locations to pick up new rights file (keys are same as in bibrecords, above)
  source:
    - host: $metadata_host
      source: $metadata_dir
      glob: "*.rights"
      dest: $rights_dir
      archive: $source/archive
    - host: USER@HOST2
      source: SOURCE
      glob: "*.rights"
      archive: $source/archive
      dest: $rights_dir
    
# Location to deposit new barcodes for rights determination
  deposit: 
# local directory to copy from
    source: $rights_dir 
    glob: "barcodes_*_feed"
# user & host to copy to
    host: $metadata_host 
# directory on host to deposit to
    dest: $metadata_dir 
# local directory to move files to after deposit
    archive: $rights_archive 
    
jira:
  wsdl: https://wush.net/jira/hathitrust/rpc/soap/jirasoapservice-v2?wsdl
  username: USERNAME
  password: PASSWORD
  from: FROM_EMAIL
  to: TO_EMAIL

# for grin_reports.pl
ctools:
  username: USERNAME
  password: PASSWORD
  url: https://DOMAIN/dav/SITE

# for get_brittle_books.pl
rejected_books:
  local_user: USERNAME
  scp_user: USERNAME
  host: HOSTNAME
  source_path_name: PATHNAME
  destination_path: PATH

dataset:
  repository: /htprep/datasets/pt/obj
  threads: 8
#
# A perl snippet returning the software name and version for each 'tool' code
# in the PREMIS events below. $self is the HTFeed::METS stage generating the
# PREMIS events.
premis_tools:
    GROOVE: $FindBin::Script . " " . HTFeed::Version::get_feed_version_number();
    EXIFTOOL: $self->perl_mod_version('Image::ExifTool');
    XERCES: $self->local_directory_version('xerces-c');
    JHOVE: $self->local_directory_version('jhove');
    DIGEST_MD5: $self->perl_mod_version('Digest::MD5');
    GPG: $self->system_version('gnupg');
    ZIP: $self->local_directory_version('zip');
    KDU_COMPRESS: $self->local_directory_version('kakadu');

# Location of the symlinks for 'local directory version'
premis_tool_local: /l/local
